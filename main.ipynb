{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import packages**\n",
        "\n"
      ],
      "metadata": {
        "id": "h4iNACus5qwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7hQE6gvvST4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dense, Reshape, Conv2DTranspose,\\\n",
        "   Activation, BatchNormalization, ReLU, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data**"
      ],
      "metadata": {
        "id": "I7XRMT6k5-zI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_image_path ='../cifar100-dataset'\n",
        "Test_image_path ='../set5-dataset'"
      ],
      "metadata": {
        "id": "pcejPRRw5aSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add gaussian noise to training and testing data**"
      ],
      "metadata": {
        "id": "TYXepgAh6CYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_factor = 0.1\n",
        "train_data_noisy = train_data_clean + noise_factor * numpy.random.normal(loc=0.0, scale=0.1, size=(32, 32, 3))\n",
        "train_data_noisy = numpy.clip(train_data_noisy, 0., 1.)\n",
        "test_data_noisy = test_data_clean + noise_factor * numpy.random.normal(loc=0.0, scale=0.1, size=(32, 32, 3))\n",
        "test_data_noisy = numpy.clip(test_data_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "mB-lM5pA5pC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize data**"
      ],
      "metadata": {
        "id": "wkkheQKG6dPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 4\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(train_data_clean[idx])\n",
        "plt.title('Original image')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(train_data_noisy[idx])\n",
        "plt.title('Image with noise')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xdYlBp9T6ZeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create model**"
      ],
      "metadata": {
        "id": "Fl14pzT-6oHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(x, filters, kernel_size, strides=2):\n",
        "   x = Conv2D(filters=filters,\n",
        "              kernel_size=kernel_size,\n",
        "              strides=strides,\n",
        "              padding='same')(x)\n",
        "   x = BatchNormalization()(x)\n",
        "   x = ReLU()(x)\n",
        "   return x\n",
        "def deconv_block(x, filters, kernel_size):\n",
        "   x = Conv2DTranspose(filters=filters,\n",
        "                       kernel_size=kernel_size,\n",
        "                       strides=2,\n",
        "                       padding='same')(x)\n",
        "   x = BatchNormalization()(x)\n",
        "   x = ReLU()(x)\n",
        "   return x"
      ],
      "metadata": {
        "id": "N5c1khjb6gzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "tic=time.clock()\n",
        "def denoising_autoencoder():\n",
        "   dae_inputs = Input(shape=(32, 32, 3), name='dae_input')\n",
        "   conv_block1 = conv_block(dae_inputs, 32, 3)\n",
        "   conv_block2 = conv_block(conv_block1, 64, 3)\n",
        "   conv_block3 = conv_block(conv_block2, 128, 3)\n",
        "   conv_block4 = conv_block(conv_block3, 256, 3)\n",
        "   conv_block5 = conv_block(conv_block4, 256, 3, 1)\n",
        "   deconv_block1 = deconv_block(conv_block5, 256, 3)\n",
        "   merge1 = Concatenate()([deconv_block1, conv_block3])\n",
        "   deconv_block2 = deconv_block(merge1, 128, 3)\n",
        "   merge2 = Concatenate()([deconv_block2, conv_block2])\n",
        "   deconv_block3 = deconv_block(merge2, 64, 3)\n",
        "   merge3 = Concatenate()([deconv_block3, conv_block1])\n",
        "   deconv_block4 = deconv_block(merge3, 32, 3)\n",
        "   final_deconv = Conv2DTranspose(filters=3,\n",
        "                       kernel_size=3,\n",
        "                       padding='same')(deconv_block4)\n",
        "   dae_outputs = Activation('sigmoid', name='dae_output')(final_deconv) \n",
        "   return Model(dae_inputs, dae_outputs, name='dae')\n",
        "dae=denoising_autoencoder()\n",
        "dae.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "dae.fit(train_data_noisy,\n",
        "       train_data_clean,\n",
        "       validation_data=(test_data_noisy, test_data_clean),\n",
        "       epochs=40,\n",
        "       batch_size=128,\n",
        "       callbacks=[checkpoint])\n",
        "toc=time.clock()"
      ],
      "metadata": {
        "id": "WMVGvT936s_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "toc-tic"
      ],
      "metadata": {
        "id": "OqxANZbG6yTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dae.load_weights('best_model.h5')\n",
        "test_data_denoised = dae.predict(test_data_noisy)"
      ],
      "metadata": {
        "id": "5XTUc1Th62io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dae.summary()"
      ],
      "metadata": {
        "id": "TEwQBkUK6-Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize results**"
      ],
      "metadata": {
        "id": "w0m3Y1q57PkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "print(\"Original Images \")\n",
        "for i in range(0,5,1):\n",
        "    plt.subplot(2, 10, i+1)\n",
        "    plt.imshow(test_data_clean[i]) \n",
        "plt.savefig(\"Original Images.png\")\n",
        "plt.show()\n",
        "plt.figure(figsize=(20, 20))\n",
        "print(\"Noisy Images\")\n",
        "for i in range(0,5,1):\n",
        "    plt.subplot(2, 10, i+1)\n",
        "    plt.imshow(test_data_noisy[i]) \n",
        "plt.savefig(\"Noisy Images.png\")\n",
        "plt.show()\n",
        "plt.figure(figsize=(20, 20))\n",
        "print(\"Denoised Images\")\n",
        "for i in range(0,5,1):\n",
        "    plt.subplot(2, 10, i+1)\n",
        "    plt.imshow(test_data_denoised[i]) \n",
        "plt.savefig(\"Denoised Images.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gHAI2oD-7B3m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}